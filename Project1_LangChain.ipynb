{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/SZ2WhqQfzbBNMdizF/eF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaheer9023/Quarter3_Projects/blob/main/Project1_LangChain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mjXZnb8XA-1R"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "GEMINI_API_KEY = userdata.get('2.O_exp')\n",
        "os.environ['GEMINI_API_KEY'] = GEMINI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet langchain_google_genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOmgYiqZDjnm",
        "outputId": "33a4d108-41f5-4412-dec0-82790a68e176"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Define the prompt templates\n",
        "prompts = {\n",
        "    \"first\": PromptTemplate(\n",
        "        input_variables=[\"text\"],\n",
        "        template=\"\"\"\n",
        "Provide a detailed explanation of the topic: \"{text}\".\n",
        "\n",
        "The explanation should:\n",
        "- Be clear and easy to understand for a general audience.\n",
        "- Include relevant examples or applications, if possible.\n",
        "- Avoid unnecessary jargon while maintaining accuracy.\n",
        "\"\"\"\n",
        "    ),\n",
        "    \"second\": PromptTemplate(\n",
        "        input_variables=[\"first_response\"],\n",
        "        template=\"\"\"\n",
        "Based on the following response: \"{first_response}\", create a detailed markdown explanation.\n",
        "\n",
        "The markdown explanation should include:\n",
        "# Introduction\n",
        "A brief overview of the topic.\n",
        "## Key Concepts\n",
        "Main ideas or points related to the topic.\n",
        "\n",
        "## In-depth Analysis\n",
        "A deeper exploration of critical subtopics or concepts.\n",
        "\n",
        "## Examples or Applications\n",
        "Relevant real-world examples, applications, or scenarios.\n",
        "\n",
        "## Conclusion\n",
        "A summary that reinforces the key takeaways.\n",
        "\"\"\"\n",
        "    ),\n",
        "    \"third\": PromptTemplate(\n",
        "        input_variables=[\"second_response\"],\n",
        "        template=\"\"\"\n",
        "Convert the following detailed explanation into a well-structured image generation prompt:\n",
        "{second_response}\n",
        "\n",
        "The image generation prompt should:\n",
        "- Be specific, vivid, and descriptive.\n",
        "- Highlight key visual elements, styles, or themes.\n",
        "- Provide sufficient details to create a realistic or artistic image.\n",
        "- Avoid ambiguity to ensure accurate image generation.\n",
        "\"\"\"\n",
        "    ),\n",
        "}\n",
        "\n",
        "# Configure the ChatGoogleGenerativeAI model with different settings\n",
        "llm_configurations = {\n",
        "    \"first\": ChatGoogleGenerativeAI(\n",
        "        api_key=GEMINI_API_KEY,\n",
        "        model=\"gemini-2.0-flash-exp\",\n",
        "        temperature=0.6\n",
        "    ),\n",
        "    \"second\": ChatGoogleGenerativeAI(\n",
        "        api_key=GEMINI_API_KEY,\n",
        "        model=\"gemini-2.0-flash-exp\",\n",
        "        temperature=0.1,\n",
        "        max_output_tokens=1000\n",
        "    ),\n",
        "    \"third\": ChatGoogleGenerativeAI(\n",
        "        api_key=GEMINI_API_KEY,\n",
        "        model=\"gemini-2.0-flash-exp\",\n",
        "        temperature=0.5,\n",
        "        max_output_tokens=300\n",
        "    ),\n",
        "}\n",
        "\n",
        "# Create the chains\n",
        "chains = {\n",
        "    \"first\": prompts[\"first\"] | llm_configurations[\"first\"],\n",
        "    \"second\": prompts[\"second\"] | llm_configurations[\"second\"],\n",
        "    \"third\": prompts[\"third\"] | llm_configurations[\"third\"],\n",
        "}\n",
        "\n",
        "# Input text for the chain\n",
        "text = \"langchain uses\"\n",
        "\n",
        "# Invoke the chains\n",
        "first_response = chains[\"first\"].invoke({\"text\": text})\n",
        "print(\"\\n\\n\\nFirst chain:\\n\\n\")\n",
        "display(Markdown(first_response.content))\n",
        "\n",
        "second_response = chains[\"second\"].invoke({\"first_response\": first_response.content})\n",
        "print(\"\\n\\n\\nSecond chain:\\n\\n\")\n",
        "display(Markdown(second_response.content))\n",
        "\n",
        "third_response = chains[\"third\"].invoke({\"second_response\": second_response.content})\n",
        "print(\"\\n\\n\\nThird chain:\\n\\n\")\n",
        "display(Markdown(third_response.content))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D5HunI0oDnO2",
        "outputId": "4539ad36-2e17-4d77-df5f-825537ec4766"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "First chain:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, let's break down what \"LangChain uses\" means in a clear and accessible way.\n\n**Imagine you have a super-powered language model, like the one that powers ChatGPT. It's incredibly good at understanding and generating text. But, on its own, it's a bit like a brilliant mind trapped in a box. It can't easily access external information, remember past conversations, or interact with other tools.**\n\nThis is where LangChain comes in. Think of LangChain as a **toolkit or framework that helps you build applications using these powerful language models.** It's like giving that brilliant mind a set of tools, instructions, and a way to connect with the outside world.\n\n**So, what are LangChain's main uses?** We can categorize them into a few key areas:\n\n1. **Connecting to Data Sources:**\n\n   * **The Problem:** Language models often lack up-to-date information or specific knowledge. They can't just magically know about your company's internal documents, the latest news, or information stored in a database.\n   * **LangChain's Solution:** LangChain provides tools to connect language models to various data sources, such as:\n        * **PDFs, Word documents, text files:** It can read and understand the content of these files.\n        * **Websites and APIs:** It can access real-time information from the internet.\n        * **Databases:** It can query and retrieve data from structured databases.\n        * **Vector Databases:** These are specialized databases that store data in a way that's easily searchable by meaning, allowing the language model to find relevant information quickly.\n   * **Example:** Imagine you want to build a chatbot that can answer questions about your company's policies. LangChain can connect the language model to your company's policy documents, allowing the chatbot to provide accurate answers based on that specific information.\n\n2. **Chaining Actions and Conversations:**\n\n   * **The Problem:** Language models are good at single tasks, but complex applications often require a sequence of actions. For instance, you might need to first search for information, then summarize it, and finally answer a question.\n   * **LangChain's Solution:** LangChain enables you to create \"chains\" of actions. You can define a sequence of steps, where the output of one step becomes the input for the next. This allows you to build more sophisticated workflows.\n   * **Example:** You could create a chain that first searches the internet for information about a particular topic, then summarizes the top results, and finally generates a blog post based on that summary.\n\n3. **Adding Memory and Context:**\n\n   * **The Problem:** Language models are typically stateless. They don't remember previous interactions, making it difficult to have meaningful conversations.\n   * **LangChain's Solution:** LangChain provides tools to add \"memory\" to language models. This allows them to remember previous turns in a conversation, user preferences, or other relevant context.\n   * **Example:** In a customer service chatbot, LangChain can help the bot remember the user's previous questions, the products they've viewed, and their order history, allowing for a more personalized and helpful interaction.\n\n4. **Using Tools and Agents:**\n\n   * **The Problem:** Language models are great at language tasks, but they can't directly perform actions like sending emails, making calculations, or interacting with other software.\n   * **LangChain's Solution:** LangChain allows you to create \"agents\" that can use external tools. You can define a set of tools (like a calculator, a search engine, or an email client) and then tell the agent how to use them to achieve a goal.\n   * **Example:** You could create an agent that can book flights. The agent would use tools to search for flights, check availability, and make a booking, based on the user's request.\n\n5. **Building Custom Applications:**\n\n   * **The Problem:** It can be difficult to build specific applications using language models directly.\n   * **LangChain's Solution:** LangChain provides a modular and flexible framework that allows you to combine different components to build custom applications. It handles the complexities of integrating language models with other tools, allowing you to focus on the specific logic of your application.\n   * **Example:** You could use LangChain to build a code generation tool that takes natural language descriptions and generates code in a specific programming language.\n\n**In simpler terms:**\n\nLangChain is like a set of Lego bricks for building applications with language models. It provides the building blocks (connecting to data, chaining actions, adding memory, etc.), and you can assemble them in different ways to create a variety of applications.\n\n**Think of it like this:**\n\n* **Language Model:** The brilliant mind (the powerful language processing engine)\n* **LangChain:** The toolkit (the tools, instructions, and connections)\n* **Application:** The final product (the chatbot, the summarization tool, the code generator, etc.)\n\n**Key Takeaway:** LangChain doesn't replace the language model. Instead, it *enhances* its capabilities by giving it access to tools, data, and context, enabling you to build more powerful and useful applications. It's the bridge between the raw power of language models and the real-world applications we can build with them.\n\nHopefully, this explanation provides a clear and understandable picture of what LangChain is used for. It's a powerful tool that's rapidly changing how we interact with and leverage the power of language models.\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Second chain:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```markdown\n# Understanding LangChain: A Toolkit for Building Powerful Language Model Applications\n\n## Introduction\n\nThis document provides a detailed explanation of LangChain, a powerful framework designed to enhance the capabilities of large language models (LLMs) like those powering ChatGPT. While LLMs are incredibly adept at understanding and generating text, they often lack the ability to access external information, remember past interactions, or interact with other tools. LangChain bridges this gap by providing a toolkit that allows developers to build sophisticated applications leveraging the power of LLMs. Think of it as giving a brilliant mind the tools and connections it needs to interact with the real world.\n\n## Key Concepts\n\n*   **Language Models (LLMs):** The core technology, such as GPT-3 or similar models, that excels at understanding and generating human-like text.\n*   **LangChain:** A framework or toolkit that provides the necessary components to build applications using LLMs. It doesn't replace the LLM but rather enhances its capabilities.\n*   **Applications:** The final products built using LLMs and LangChain, such as chatbots, summarization tools, code generators, and more.\n*   **Key Functionalities:** LangChain provides functionalities in several key areas:\n    *   Connecting to Data Sources\n    *   Chaining Actions and Conversations\n    *   Adding Memory and Context\n    *   Using Tools and Agents\n    *   Building Custom Applications\n\n## In-depth Analysis\n\n### 1. Connecting to Data Sources\n\n*   **Problem:** LLMs often lack access to up-to-date or specific information. They cannot inherently know about your company's internal documents, the latest news, or data stored in databases.\n*   **LangChain's Solution:** LangChain provides tools to connect LLMs to various data sources:\n    *   **Document Files:** Reads and understands content from PDFs, Word documents, and text files.\n    *   **Websites and APIs:** Accesses real-time information from the internet.\n    *   **Databases:** Queries and retrieves data from structured databases.\n    *   **Vector Databases:** Uses specialized databases that store data in a way that's easily searchable by meaning, allowing the LLM to find relevant information quickly.\n*   **Significance:** This allows LLMs to operate on specific, relevant, and up-to-date information, making them much more useful in real-world scenarios.\n\n### 2. Chaining Actions and Conversations\n\n*   **Problem:** LLMs are good at single tasks, but complex applications often require a sequence of actions.\n*   **LangChain's Solution:** Enables the creation of \"chains\" of actions, where the output of one step becomes the input for the next.\n*   **Significance:** This allows for the creation of sophisticated workflows, enabling the LLM to perform complex tasks that require multiple steps.\n\n### 3. Adding Memory and Context\n\n*   **Problem:** LLMs are typically stateless, meaning they don't remember previous interactions, making it difficult to have meaningful conversations.\n*   **LangChain's Solution:** Provides tools to add \"memory\" to LLMs, allowing them to remember previous turns in a conversation, user preferences, or other relevant context.\n*   **Significance:** This enables more personalized and context-aware interactions, making applications more user-friendly and effective.\n\n### 4. Using Tools and Agents\n\n*   **Problem:** LLMs are great at language tasks but cannot directly perform actions like sending emails, making calculations, or interacting with other software.\n*   **LangChain's Solution:** Allows the creation of \"agents\" that can use external tools. You can define a set of tools and instruct the agent on how to use them to achieve a goal.\n*   **Significance:** This extends the capabilities of LLMs beyond language tasks, allowing them to interact with the real world and perform actions.\n\n### 5. Building Custom Applications\n\n*   **Problem:** Building specific applications using LLMs directly can be complex and challenging.\n*   **LangChain's Solution:** Provides a modular and flexible framework that allows developers to combine different components to build custom applications.\n*   **Significance:** This simplifies the process of building complex applications, allowing developers to focus on the specific logic of their application rather than the complexities of integrating LLMs with other tools.\n\n## Examples or Applications\n\n*   **Chatbots:** LangChain can be used to build chatbots that can access company documents, remember past conversations, and use tools to perform actions like booking appointments.\n*   **Summarization Tools:** LangChain can be used to build tools that can summarize large documents or articles by first accessing the content, then processing it through the LLM.\n*   **Code Generators:** LangChain can be used to build"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Third chain:\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, here's a structured image generation prompt based on the provided LangChain explanation, designed to be specific, vivid, and descriptive:\n\n**Image Generation Prompt:**\n\n**Subject:** A stylized, interconnected network diagram representing LangChain's functionality, overlaid on a futuristic cityscape.\n\n**Composition:**\n\n*   **Central Element:** A glowing, stylized brain (representing the LLM) at the center of the image. It should have a neural network-like texture with light emanating from within.\n*   **Connecting Lines:** Radiating outwards from the brain are numerous glowing lines, each representing a connection to different elements. These lines should be a gradient of light blue to vibrant purple, suggesting the flow of information.\n*   **Data Source Icons:** At the end of some of these connecting lines are icons representing different data sources:\n    *   A stylized document icon (for document files).\n    *   A globe icon with network lines (for websites and APIs).\n    *   A database cylinder icon (for databases).\n    *   A cube-like icon with a vector grid (for vector databases).\n*   **Chain of Actions:** Some of the connecting lines should form a chain, with small, interconnected gears or cogs along the line, symbolizing the chaining of actions.\n*   **Memory Element:** A small, glowing memory chip icon is connected to the central brain, representing the ability to store and recall previous interactions.\n*   **"
          },
          "metadata": {}
        }
      ]
    }
  ]
}